{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" How to use C3D network. \"\"\"\n",
    "import numpy as np\n",
    "import cv2\n",
    "#import cv\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "import os\n",
    "from os.path import join\n",
    "from glob import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import skimage.io as io\n",
    "from skimage.transform import resize\n",
    "from tqdm import tqdm\n",
    "from C3D_model import C3D\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_sport_clip(clip_name, verbose=True):\n",
    "    \"\"\"\n",
    "    Loads a clip to be fed to C3D for classification.\n",
    "    TODO: should I remove mean here?\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    clip_name: str\n",
    "        the name of the clip (subfolder in 'data').\n",
    "    verbose: bool\n",
    "        if True, shows the unrolled clip (default is True).\n",
    "    Returns\n",
    "    -------\n",
    "    Tensor\n",
    "        a pytorch batch (n, ch, fr, h, w).\n",
    "    \"\"\"\n",
    "    #print(clip_name)\n",
    "    clip = sorted(glob(join( clip_name, '*.png')))\n",
    "#     for f in clip:\n",
    "#         print(f)\n",
    "#     fs=[]\n",
    "#     for frame in clip:\n",
    "#         frame = io.imread(frame)\n",
    "#         result = np.zeros(frame.shape,dtype=np.float32)\n",
    "#         cv2.normalize(frame,result,0,1,cv2.NORM_MINMAX)\n",
    "#         fs.append([resize(result, output_shape=(112, 200),\n",
    "#                             preserve_range=True) ])\n",
    "#     clip = np.array(fs)\n",
    "    #print(clip)\n",
    "    clip = np.array([resize(io.imread(frame),\n",
    "                            output_shape=(112, 200),\n",
    "                            preserve_range=True,\n",
    "                            mode='constant') for frame in clip])\n",
    "    clip = clip[:, :, 44:44+112, :]  # crop centrally\n",
    "\n",
    "    if verbose:\n",
    "        clip_img = np.reshape(clip.transpose(1, 0, 2, 3),(112, 41 * 112, 3))\n",
    "#         plt.imshow(clip_img.astype(np.uint8))\n",
    "#         plt.show()\n",
    "\n",
    "    clip = clip.transpose(3, 0, 1, 2)  # ch, fr, h, w\n",
    "    clip = np.expand_dims(clip, axis=0)  # batch axis\n",
    "    clip = np.float32(clip)\n",
    "\n",
    "    return torch.from_numpy(clip)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.io as scio\n",
    "data = scio.loadmat('save.mat')\n",
    "allX=data['xTrain']\n",
    "allY=data['yTrain']\n",
    "testX=data['xTest']\n",
    "testY=data['yTest']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "C3D(\n",
       "  (features): Sequential(\n",
       "    (0): Conv3d(3, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "    (1): ReLU(inplace)\n",
       "    (2): MaxPool3d(kernel_size=(1, 2, 2), stride=(1, 2, 2), padding=0, dilation=1, ceil_mode=False)\n",
       "    (3): Conv3d(64, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "    (4): ReLU(inplace)\n",
       "    (5): MaxPool3d(kernel_size=(2, 2, 2), stride=(2, 2, 2), padding=0, dilation=1, ceil_mode=False)\n",
       "    (6): Conv3d(128, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "    (7): ReLU(inplace)\n",
       "    (8): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "    (9): ReLU(inplace)\n",
       "    (10): MaxPool3d(kernel_size=(2, 2, 2), stride=(2, 2, 2), padding=0, dilation=1, ceil_mode=False)\n",
       "    (11): Conv3d(256, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "    (12): ReLU(inplace)\n",
       "    (13): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "    (14): ReLU(inplace)\n",
       "    (15): MaxPool3d(kernel_size=(2, 2, 2), stride=(2, 2, 2), padding=0, dilation=1, ceil_mode=False)\n",
       "    (16): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "    (17): ReLU(inplace)\n",
       "    (18): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "    (19): ReLU(inplace)\n",
       "    (20): MaxPool3d(kernel_size=(2, 2, 2), stride=(2, 2, 2), padding=(0, 1, 1), dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (classifier): Sequential(\n",
       "    (0): Linear(in_features=16384, out_features=4096, bias=True)\n",
       "    (1): ReLU(inplace)\n",
       "    (2): Dropout(p=0.5)\n",
       "    (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "    (4): ReLU(inplace)\n",
       "    (5): Dropout(p=0.5)\n",
       "    (6): Linear(in_features=4096, out_features=2, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net = C3D()\n",
    "device=torch.device('cuda:1')\n",
    "net.to(device)\n",
    "net.load_state_dict(torch.load('./myC3D.pickle'))\n",
    "net.eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "testX=allX\n",
    "testY=allY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "testX=torch.from_numpy(np.array(testX)).type(torch.float)\n",
    "\n",
    "testX = Variable(testX)\n",
    "testX = testX.cuda(1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()\n",
    "gc.collect()\n",
    "testLoss=[]\n",
    "predictions=[]\n",
    "for i in range(0,len(testX),1):\n",
    "    \n",
    "    prediction = net.predict(testX[i:i+1])\n",
    "#     print(prediction)\n",
    "#     print(testY[i])\n",
    "#     print()\n",
    "    predictions.append(prediction.data.cpu().numpy())\n",
    "    #print(Variable(prediction))\n",
    "    #print(Variable(y))\n",
    "#     loss = criterion(prediction,testY[i:i+2].squeeze())\n",
    "#     testLoss.append(loss.item())\n",
    "\n",
    "#     print(d,loss.item())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "666\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "print(len(predictions))\n",
    "error = 0\n",
    "for i in range(len(predictions)):\n",
    "    if predictions[i]!=testY[i]:\n",
    "        error+=1\n",
    "print(1-error/len(predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYYAAAD8CAYAAABzTgP2AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nrkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f90c59832b0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "plt.plot(range(len(predictions)),predictions-testY,'ro')\n",
    "# plt.plot(range(len(testY)),,'bx')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(net.state_dict(),'./myC3D924.pickle')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
